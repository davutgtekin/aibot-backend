// server.js - NIHAI Ã‡Ã–ZÃœM: VERTEX AI ENTEGRASYONU
require("dotenv").config();
const express = require("express");
const cors = require("cors");
// YENÄ° KÃœTÃœPHANE: ArtÄ±k Vertex AI kullanÄ±yoruz.
const { VertexAI } = require('@google-cloud/vertexai');

const app = express();
app.use(cors());
app.use(express.json());

const PORT = process.env.PORT || 5000;

// Vertex AI'Ä± projemizin kimliÄŸi ve konumu ile baÅŸlatÄ±yoruz.
// Kimlik doÄŸrulamasÄ± iÃ§in API anahtarÄ± yerine otomatik olarak
// Google Cloud yetkilendirmesini kullanÄ±r, bu daha gÃ¼venlidir.
const vertex_ai = new VertexAI({
  project: process.env.GCP_PROJECT_ID,
  location: process.env.GCP_LOCATION,
});

// KullanacaÄŸÄ±mÄ±z modeli belirliyoruz.
const model = "gemin-2.5-pro";
 // Bu, Vertex AI'daki EN stabil ve genel model adÄ±dÄ±r.

const generativeModel = vertex_ai.getGenerativeModel({
  model: model,
});

app.get("/", (req, res) => {
  res.send("Chatbot Backend Ã‡alÄ±ÅŸÄ±yor âœ… (Vertex AI ile)");
});

app.post("/chat", async (req, res) => {
  try {
    const userMessage = req.body.message;

    const reqPayload = {
      contents: [{ role: 'user', parts: [{ text: userMessage }] }],
    };

    const result = await generativeModel.generateContent(reqPayload);
    
    // Vertex AI'dan gelen cevap formatÄ± biraz daha farklÄ±dÄ±r, ona gÃ¶re alÄ±yoruz.
    const reply = result.response.candidates[0].content.parts[0].text;

    res.json({ reply });

  } catch (error) {
    console.error("--- KRÄ°TÄ°K HATA (VERTEX AI) ---");
    console.error(error);
    console.error("---------------------------------");
    res.status(500).json({ reply: "ÃœzgÃ¼nÃ¼m, Vertex AI sunucusunda bir hata oluÅŸtu." });
  }
});

app.listen(PORT, () => {
  console.log(`Server ${PORT} portunda Ã§alÄ±ÅŸÄ±yor ğŸš€`);
});